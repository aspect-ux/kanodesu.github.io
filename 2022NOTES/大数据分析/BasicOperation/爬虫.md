##### 爬虫

* 解码

  使用python内置的`urllib.request`模块就可以获得网页字节码，乱码；通过对网页解码，就可以得到原码的字符串;`request`更推荐用；

* 文本解析库`BeautifulSoup`

  能够自动将输入文档转化成`unicode`,即字符串形式，编码为`utf-8`

  以下为方法：

  > #第一个参数是html文本字符串,第二个是解析器
  >
  > `BeautifulSoup(markup,"html.parser")`
  >
  > `html.parser = "lxml" | "xml" |"html5lib"`

  解析器用来解析html文本，`BeautifulSoup`用来定位标签结点

  可以使用**标准选择器**和**`css选择器`**

  其中标准选择器有遍历文档树和搜索文档树

  * 遍历文档树

    遍历，慢，只能匹配到与之相同的第一个标签；

    text = """ <html></hmtl>     """

    ```python
    soup.p.name
    soup.p.string
    soup.p.attrs
    soup.p['class']#获取属性值
    ```

  * 搜索文档树

    `find(),find_all()方法`
  
   **CSS选择器**
  
  * 基本语法
  
    `soup.select('.panel .panel-heading')`
  
    就是通过选择类，注意有空格
  
    `soup.select('ul li')`
  
    选择`ul`下面的li标签
  
    `soup.select('#list-2 .element')`
  
    #代表id，用来查找id为”list-2",类名为element的元素
  
    `soup.select('ul')[i]`
  
    也可以通过结点来选择
  
  * more
  
    ```python
    #1
    for ul  in soup.select('ul'):
        print(ul.select('li'))
    #2
    for ul in soup.select('ul'):
        print(ul['id'])        #1
        print(ul.attrs['id'])  #2这两种方法都能获取属性如id
    #3
    for li in soup.select('li'):
        print('Get Text:',li.get_text())
        print('String:',li.string)
    ```

* 应对反爬

  * 伪装成浏览器

    ```python
    #requests: 添加headers
    
    #requests可以直接构造请求并发起。
    import requests
    url='https://www.douban.com'
    headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36',
    }#可以通过chrome://version获取用户代理
    get_response = requests.get(url,headers=headers)
    print(get_response.text) 
    print(get_response.content)
    
    ```

  * 使用代理IP和控制访问频率

    ```python
    Proxy_IP = 'http:\\111.72.126.111:8080'
    response = requests.get(url,proxies = Proxy_IP)
    time.sleep(2)
    ```

    

##### 实验

* `url`参数格式

  **<协议>：//<用户名>：<密码>@<主机域名或者`ip`地址>：<端口号>/<路径>；<参数>？<查询>#<片段>**

[湖北大学吧-百度贴吧--沙湖之滨，长江之畔，一环中最闪亮那枚星。--本吧是湖北大学师生校友在百度旗下的电子论坛，同时也欢迎有意报考湖北大学的高中毕业生、本科毕业生前来咨询。本吧诚迎五湖四海之士，同时亦希望 (baidu.com)](https://tieba.baidu.com/f?kw=湖北大学&ie=utf-8&tp=0&pn=49)

pn是page

